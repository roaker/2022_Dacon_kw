{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import easydict\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import sys\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "from torch.nn.modules.transformer import _get_activation_fn\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 압축풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvRN_jNoAMCZ",
    "outputId": "4e38d941-5acd-4fa9-ea1e-b94a5b486bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGzFTzXYAMIo",
    "outputId": "a00ccb34-1d30-4164-c834-a36bff978720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data_2.zip\n",
      "  inflating: dirty_mnist_2nd.zip     "
     ]
    }
   ],
   "source": [
    "!cp \"/content/drive/MyDrive/sw해커톤/data_2.zip\" \"data_2.zip\"\n",
    "!unzip \"data_2.zip\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB_i0Jl4AMPj"
   },
   "outputs": [],
   "source": [
    "!mkdir \"./dirty_mnist\"\n",
    "!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\n",
    "!mkdir \"./test_dirty_mnist\"\n",
    "!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9dK3Mkm93yq"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"image_path\": \"./dirty_mnist/\",\n",
    "    \"label_path\": \"/content/dirty_mnist_2nd_answer.csv\",\n",
    "    \"kfold_idx\": 0, ## 0~4까지 바꿔 가면서 5번 학습. \n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\": 64\n",
    "    \"lr\": 1e-3,\n",
    "    \"patience\": 20,\n",
    "    \"resume\": None,\n",
    "    \"device\": device,\n",
    "    \"comments\": None,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPPLP0-w9306",
    "outputId": "8e03f0fd-e5b9-4276-98ff-49d54e9403e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/dropout/cutout.py:52: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class DatasetMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, label_df, transforms):        \n",
    "        self.image_folder = image_folder   \n",
    "        self.label_df = label_df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        image_fn = self.image_folder +\\\n",
    "            str(self.label_df.iloc[index,0]).zfill(5) + '.png'\n",
    "                                              \n",
    "        image = cv2.imread(image_fn, cv2.IMREAD_GRAYSCALE)        \n",
    "        image = image.reshape([256, 256, 1])\n",
    "\n",
    "        label = self.label_df.iloc[index,1:].values.astype('float')\n",
    "\n",
    "        if self.transforms:            \n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "basic_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Lambda(lambda x: torch.cat([x, x, x], 0)), \n",
    "])    \n",
    "    \n",
    "mnist_transforms = {\n",
    "    'train' : albumentations.Compose([\n",
    "            albumentations.RandomRotate90(),\n",
    "            albumentations.OneOf([\n",
    "                albumentations.GridDistortion(distort_limit=(-0.3, 0.3), border_mode=cv2.BORDER_CONSTANT, p=1),\n",
    "                albumentations.ShiftScaleRotate(rotate_limit=15, border_mode=cv2.BORDER_CONSTANT, p=1),        \n",
    "                albumentations.ElasticTransform(alpha_affine=10, border_mode=cv2.BORDER_CONSTANT, p=1),\n",
    "            ], p=1),    \n",
    "            albumentations.Cutout(num_holes=3, max_h_size=8, max_w_size=8, fill_value=0),\n",
    "            albumentations.pytorch.ToTensorV2(),\n",
    "        ]),\n",
    "    'valid' : albumentations.Compose([        \n",
    "        albumentations.pytorch.ToTensorV2(),\n",
    "        ]),\n",
    "    'test' : albumentations.Compose([        \n",
    "        albumentations.pytorch.ToTensorV2(),\n",
    "        ]),\n",
    "}\n",
    "\n",
    "def train(train_loader, model, loss_func, device, optimizer, scheduler=None):\n",
    "    n = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    model.train()    \n",
    "\n",
    "    with tqdm(train_loader, total=len(train_loader), desc=\"Train\", file=sys.stdout) as iterator:\n",
    "        for train_x, train_y in iterator:\n",
    "            \n",
    "            train_x = torch.stack([x.permute(1,2,0) for x in train_x])\n",
    "            train_x = train_x.numpy()\n",
    "            train_x = torch.stack([mnist_transforms[\"train\"](image=k)[\"image\"] for k in train_x])\n",
    "            \n",
    "            train_x = train_x.float().to(device)\n",
    "            train_y = train_y.float().to(device)\n",
    "            \n",
    "            output = model(train_x)\n",
    "            \n",
    "            loss = loss_func(output, train_y)\n",
    "            \n",
    "            n += train_x.size(0)\n",
    "            running_loss += loss.item() * train_x.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "\n",
    "            output = output > 0.5\n",
    "            running_corrects += (output == train_y).sum()\n",
    "            epoch_acc = running_corrects / train_y.size(1) / n\n",
    "\n",
    "            log = 'loss - {:.5f}, acc - {:.5f}'.format(epoch_loss, epoch_acc)\n",
    "            \n",
    "            iterator.set_postfix_str(log)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(valid_loader, model, loss_func, device, scheduler=None):\n",
    "    n = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with tqdm(valid_loader, total=len(valid_loader), desc=\"Valid\", file=sys.stdout) as iterator:\n",
    "        for train_x, train_y in iterator:\n",
    "            train_x = train_x.float().to(device)\n",
    "            train_y = train_y.float().to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(train_x)\n",
    "            \n",
    "            loss = loss_func(output, train_y)\n",
    "\n",
    "            n += train_x.size(0)\n",
    "            running_loss += loss.item() * train_x.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "\n",
    "            output = output > 0.5\n",
    "            running_corrects += (output == train_y).sum()\n",
    "            epoch_acc = running_corrects / train_y.size(1) / n\n",
    "\n",
    "            log = 'loss - {:.5f}, acc - {:.5f}'.format(epoch_loss, epoch_acc)\n",
    "\n",
    "            iterator.set_postfix_str(log)\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kiW6jcv933C"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.features = models.efficientnet_v2_m(weights=\"DEFAULT\")\n",
    "        #self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fn1 = nn.Linear(1000, 128)\n",
    "        self.fn2 = nn.Linear(128, n_classes)\n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #x = self.gap(x).squeeze(3).squeeze(2)\n",
    "        #print(x.shape)\n",
    "        x = self.fn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fn2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cp6yc_mM4lg9",
    "outputId": "cf2be2c0-d566-472a-85b7-c8a8a639c2f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       53477460 kB\n",
      "MemFree:        16159252 kB\n",
      "MemAvailable:   51305280 kB\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 50)\n",
    "print('[info msg] arguments\\n')\n",
    "for key, value in vars(args).items():\n",
    "    print(key, \":\", value)\n",
    "print('=' * 50)\n",
    "\n",
    "assert os.path.isdir(args.image_path), 'wrong path'\n",
    "assert os.path.isfile(args.label_path), 'wrong path'\n",
    "if (args.resume):\n",
    "    assert os.path.isfile(args.resume), 'wrong path'\n",
    "assert args.kfold_idx < 5\n",
    "\n",
    "seed_everything(777)\n",
    "\n",
    "data_set = pd.read_csv(args.label_path)\n",
    "valid_idx_nb = int(len(data_set) * (1 / 5))\n",
    "valid_idx = np.arange(valid_idx_nb * args.kfold_idx, valid_idx_nb * (args.kfold_idx + 1))\n",
    "\n",
    "print('[info msg] validation fold idx !!\\n')        \n",
    "print(valid_idx)\n",
    "print('=' * 50)\n",
    "\n",
    "train_data = data_set.drop(valid_idx)\n",
    "valid_data = data_set.iloc[valid_idx]\n",
    "\n",
    "train_set = DatasetMNIST(\n",
    "    image_folder=args.image_path,\n",
    "    label_df=train_data,\n",
    "    transforms=basic_transform\n",
    ")\n",
    "\n",
    "valid_set = DatasetMNIST(\n",
    "    image_folder=args.image_path,\n",
    "    label_df=valid_data,\n",
    "    transforms=basic_transform\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_set,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "model = CNN(26)\n",
    "\n",
    "#if(args.resume):\n",
    "#    model = EfficientNet.from_name(args.model, in_channels=1, num_classes=26, dropout_rate=0.5)\n",
    "#    model.load_state_dict(torch.load(args.resume))\n",
    "#    print('[info msg] pre-trained weight is loaded !!\\n')        \n",
    "#    print(args.resume)\n",
    "#    print('=' * 50)\n",
    "\n",
    "#else:\n",
    "#    print('[info msg] {} model is created\\n'.format(args.model))\n",
    "#    model = EfficientNet.from_pretrained(args.model, in_channels=1, num_classes=26, dropout_rate=0.5, advprop=True)\n",
    "#    print('=' * 50)\n",
    "\n",
    "#if args.device == 'cuda' and torch.cuda.device_count() > 1 :\n",
    "#    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(args.device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "criterion = torch.nn.MultiLabelSoftMarginLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode='min',\n",
    "    patience=7,\n",
    "    factor=0.1,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "patience = 0\n",
    "\n",
    "date_time = datetime.now().strftime(\"%m%d%H%M%S\")\n",
    "SAVE_DIR = os.path.join('/content/drive/MyDrive/sw해커톤/m/save2', date_time)\n",
    "\n",
    "print('[info msg] training start !!\\n')\n",
    "startTime = datetime.now()\n",
    "for epoch in range(args.epochs):        \n",
    "    print('Epoch {}/{}'.format(epoch+1, args.epochs))\n",
    "    train_epoch_loss, train_epoch_acc = train(\n",
    "        train_loader=train_data_loader,\n",
    "        model=model,\n",
    "        loss_func=criterion,\n",
    "        device=args.device,\n",
    "        optimizer=optimizer,\n",
    "        )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_acc.append(train_epoch_acc)\n",
    "\n",
    "    valid_epoch_loss, valid_epoch_acc = validate(\n",
    "        valid_loader=valid_data_loader,\n",
    "        model=model,\n",
    "        loss_func=criterion,\n",
    "        device=args.device,\n",
    "        scheduler=scheduler,\n",
    "        )\n",
    "    valid_loss.append(valid_epoch_loss)        \n",
    "    valid_acc.append(valid_epoch_acc)\n",
    "\n",
    "    if best_loss > valid_epoch_loss:\n",
    "        patience = 0\n",
    "        best_loss = valid_epoch_loss\n",
    "\n",
    "        Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), os.path.join(SAVE_DIR, 'model_best.pth.tar'))\n",
    "        print('MODEL IS SAVED TO {}!!!'.format(date_time))\n",
    "        \n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience > args.patience - 1:\n",
    "            print('=======' * 10)\n",
    "            print(\"[Info message] Early stopper is activated\")\n",
    "            break\n",
    "\n",
    "elapsed_time = datetime.now() - startTime\n",
    "\n",
    "train_loss = np.array(train_loss)\n",
    "train_acc = np.array(train_acc)\n",
    "valid_loss = np.array(valid_loss)\n",
    "valid_acc = np.array(valid_acc)\n",
    "\n",
    "best_loss_pos = np.argmin(valid_loss)\n",
    "\n",
    "print('=' * 50)\n",
    "print('[info msg] training is done\\n')\n",
    "print(\"Time taken: {}\".format(elapsed_time))\n",
    "print(\"best loss is {} w/ acc {} at epoch : {}\".format(best_loss, valid_acc[best_loss_pos], best_loss_pos))    \n",
    "\n",
    "print('=' * 50)\n",
    "print('[info msg] {} model weight and log is save to {}\\n'.format(args.model, SAVE_DIR))\n",
    "\n",
    "with open(os.path.join(SAVE_DIR, 'log.txt'), 'w') as f:\n",
    "    for key, value in vars(args).items():\n",
    "        f.write('{} : {}\\n'.format(key, value))            \n",
    "\n",
    "    f.write('\\n')\n",
    "    f.write('total ecpochs : {}\\n'.format(str(train_loss.shape[0])))\n",
    "    f.write('time taken : {}\\n'.format(str(elapsed_time)))\n",
    "    f.write('best_train_loss {} w/ acc {} at epoch : {}\\n'.format(np.min(train_loss), train_acc[np.argmin(train_loss)], np.argmin(train_loss)))\n",
    "    f.write('best_valid_loss {} w/ acc {} at epoch : {}\\n'.format(np.min(valid_loss), valid_acc[np.argmin(valid_loss)], np.argmin(valid_loss)))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(valid_loss, 'o', label='valid loss')\n",
    "plt.axvline(x=best_loss_pos, color='r', linestyle='--', linewidth=1.5)\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label='train acc')\n",
    "plt.plot(valid_acc, 'o', label='valid acc')\n",
    "plt.axvline(x=best_loss_pos, color='r', linestyle='--', linewidth=1.5)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(SAVE_DIR, 'history.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIuRxw4Q93_Y"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ttach as tta\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import albumentations.pytorch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "class DatasetMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, label_df, transforms):        \n",
    "        self.image_folder = image_folder   \n",
    "        self.label_df = label_df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        image_fn = self.image_folder +\\\n",
    "            str(self.label_df.iloc[index,0]).zfill(5) + '.png'\n",
    "                                              \n",
    "        image = cv2.imread(image_fn, cv2.IMREAD_GRAYSCALE)        \n",
    "        image = image.reshape([256, 256, 1])\n",
    "\n",
    "        label = self.label_df.iloc[index,1:].values.astype('float')\n",
    "\n",
    "        if self.transforms:            \n",
    "            image = self.transforms(image=image)['image'] / 255.0\n",
    "\n",
    "        return image, label\n",
    "\n",
    "base_transforms = {\n",
    "    'test' : albumentations.Compose([        \n",
    "        albumentations.pytorch.ToTensorV2(),\n",
    "        ]),\n",
    "}\n",
    "\n",
    "#base_transforms = basic_transform = T.Compose([\n",
    "#    T.ToTensor(),\n",
    "    #T.Lambda(lambda x: torch.cat([x, x, x], 0)), \n",
    "#])\n",
    "\n",
    "#tta_transforms = tta.Compose(\n",
    "#    [\n",
    "#        tta.Rotate90(angles=[0, 90, 180, 270]),\n",
    "#    ]\n",
    "#)\n",
    "\n",
    "tta_transform = albumentations.Compose([\n",
    "            albumentations.RandomRotate90(),\n",
    "            albumentations.OneOf([\n",
    "                albumentations.GridDistortion(distort_limit=(-0.3, 0.3), border_mode=cv2.BORDER_CONSTANT, p=1),\n",
    "                albumentations.ShiftScaleRotate(rotate_limit=15, border_mode=cv2.BORDER_CONSTANT, p=1),        \n",
    "                albumentations.ElasticTransform(alpha_affine=10, border_mode=cv2.BORDER_CONSTANT, p=1),\n",
    "            ], p=1),    \n",
    "            albumentations.Cutout(num_holes=16, max_h_size=15, max_w_size=15, fill_value=0),\n",
    "            albumentations.pytorch.ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "def main():\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    args = easydict.EasyDict({\n",
    "    \"image_path\": \"C://dacon/kw/test_dirty_mnist_2nd/\",\n",
    "    \"label_path\": \"C://dacon/kw/sample_submission.csv\",\n",
    "    \"weight_path\": \"C:/Users/woghs/2022_AI/save/efficientb3_baseline/\",\n",
    "    \"out_path\": \"C://dacon/kw/\",\n",
    "    \"model\": \"efficientnet-b3\",\n",
    "    \"batch_size\": 1,\n",
    "    \"device\": device,\n",
    "})\n",
    "    \n",
    "#    parser = argparse.ArgumentParser()\n",
    "#    parser.add_argument('--image_path', type=str, default=\"./data/\")\n",
    "#    parser.add_argument('--label_path', type=str, default=\"./input/sample_submission.csv\")\n",
    "#    parser.add_argument('--weight_path', type=str, default='./input/model')\n",
    "#    parser.add_argument('--out_path', type=str, default='./output/')\n",
    "\n",
    "#    parser.add_argument('--model', type=str, default='efficientnet-b8')    \n",
    "#    parser.add_argument('--batch_size', type=int, default=4)\n",
    "\n",
    "#    parser.add_argument('--device', type=str, default=device)\n",
    "\n",
    "#    args = parser.parse_args()\n",
    "\n",
    "    assert os.path.isdir(args.image_path), 'wrong path'\n",
    "    assert os.path.isfile(args.label_path), 'wrong path'\n",
    "    assert os.path.isdir(args.weight_path), 'wrong path' \n",
    "    assert os.path.isdir(args.out_path), 'wrong path'\n",
    "\n",
    "    print('=' * 50)\n",
    "    print('[info msg] arguments')\n",
    "    for key, value in vars(args).items():\n",
    "        print(key, \":\", value)\n",
    "    \n",
    "    weights = glob(os.path.join(args.weight_path, '*.tar'))\n",
    "\n",
    "    test_df = pd.read_csv(args.label_path)\n",
    "\n",
    "    test_set = DatasetMNIST(\n",
    "        image_folder=args.image_path,\n",
    "        label_df=test_df,\n",
    "        transforms=base_transforms['test']\n",
    "    )\n",
    "\n",
    "    submission_df = copy.copy(test_df)\n",
    "\n",
    "    for weight in weights:   \n",
    "        model = EfficientNet.from_name(args.model, in_channels=1, num_classes=26)\n",
    "        model.load_state_dict(torch.load(weight, map_location=args.device))\n",
    "        print('=' * 50)\n",
    "        print('[info msg] weight {} is loaded'.format(weight))\n",
    "\n",
    "        test_data_loader = torch.utils.data.DataLoader(\n",
    "                test_set,\n",
    "                batch_size = args.batch_size,\n",
    "                shuffle = False,\n",
    "            )\n",
    "\n",
    "        model.to(args.device)\n",
    "        model.eval()\n",
    "        #tta_model = tta.ClassificationTTAWrapper(model, tta_transforms)\n",
    "\n",
    "        batch_size = args.batch_size\n",
    "        batch_index = 0\n",
    "\n",
    "        print('=' * 50)\n",
    "        print('[info msg] inference start')\n",
    "\n",
    "        for i, (images, _) in enumerate(tqdm(test_data_loader)):\n",
    "            sum_sub = model(images.cuda()) #원본\n",
    "            #print(sum_sub)\n",
    "            \n",
    "            images = images.permute(0,2,3,1).numpy()\n",
    "            \n",
    "            for j in range(9): #변형 개수 및 합치는 과정\n",
    "                sub_image = tta_transform(image=images.squeeze(0))[\"image\"].unsqueeze(0)\n",
    "                output = model(sub_image.float().cuda())\n",
    "                sum_sub = sum_sub + output\n",
    "            \n",
    "            sum_final = sum_sub/10 #평균 soft voting\n",
    "            \n",
    "            #print(sum_final)\n",
    "            \n",
    "            #images = torch.stack([tta_transforms(image=k)[\"image\"] for k in images])\n",
    "            #images = images.float().to(args.device)\n",
    "            \n",
    "            #outputs = tta_model(images).detach().cpu().numpy().squeeze() # soft\n",
    "            outputs = sum_final.detach().cpu().numpy().squeeze()\n",
    "            #print(outputs)\n",
    "            \n",
    "            #outputs = (outputs > 0.5).astype(int) # hard vote\n",
    "            batch_index = i * batch_size\n",
    "            submission_df.iloc[batch_index:batch_index+batch_size, 1:] += outputs\n",
    "    \n",
    "    submission_df.iloc[:,1:] = (submission_df.iloc[:,1:] / len(weights) > 0.5).astype(int)\n",
    "    \n",
    "    SAVE_FN = os.path.join(args.out_path, datetime.now().strftime(\"%m%d%H%M\") + '_please_submission.csv')\n",
    "\n",
    "    submission_df.to_csv(\n",
    "        SAVE_FN,\n",
    "        index=False\n",
    "        )\n",
    "\n",
    "    print('=' * 50)\n",
    "    print('[info msg] submission fils is saved to {}'.format(SAVE_FN))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aiUssvH694Bg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53Bx0fux94EC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHZ2cIAD94GK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4d_OQ7694IV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujLesUzx94MP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_0eNbgh94Og"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
